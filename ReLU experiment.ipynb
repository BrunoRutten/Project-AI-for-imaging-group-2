{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Notebook Group 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, ReLU, BatchNormalization, add,Softmax, AveragePooling2D, Dense, Input, GlobalAveragePooling2D,ELU,PReLU,LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.activations import selu, swish\n",
    "\n",
    "# disable overly verbose tensorflow logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "stdactivators = [ 'ReLU','ELU','LeakyReLU']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expansion_block(x,t,filters,block_id,LUtype):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    total_filters = t*filters\n",
    "    x = Conv2D(total_filters,1,padding='same',use_bias=False, name = prefix +'expand')(x)\n",
    "    x = BatchNormalization(name=prefix +'expand_bn')(x)\n",
    "    if LUtype in stdactivators:\n",
    "        x = eval(LUtype + \"(6,name=prefix +'expand_relu')(x)\")\n",
    "    elif LUtype == 'PReLU':\n",
    "        x = PReLU(name=prefix +'expand_relu')(x)\n",
    "    elif LUtype == 'SeLU':\n",
    "        x = selu(x)\n",
    "    elif LUtype == 'Swish':\n",
    "        x = swish(x)\n",
    "    return x\n",
    "\n",
    "def depthwise_block(x,stride,block_id,LUtype):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = DepthwiseConv2D(3,strides=(stride,stride),padding ='same', use_bias = False, name = prefix + 'depthwise_conv')(x)\n",
    "    x = BatchNormalization(name=prefix +'dw_bn')(x)\n",
    "    if LUtype in stdactivators:\n",
    "        x = eval(LUtype + \"(6,name=prefix +'dw_relu')(x)\")\n",
    "    elif LUtype == 'PReLU':\n",
    "        x = PReLU(name=prefix +'dw_relu')(x)\n",
    "    elif LUtype == 'SeLU':\n",
    "        x = selu(x)\n",
    "    elif LUtype == 'Swish':\n",
    "        x = swish(x)\n",
    "    return x\n",
    "\n",
    "def projection_block(x,out_channels,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = Conv2D(filters = out_channels,kernel_size = 1,padding='same',use_bias=False,name= prefix + 'compress')(x)\n",
    "    x = BatchNormalization(name=prefix +'compress_bn')(x)\n",
    "    return x\n",
    "\n",
    "def Bottleneck(x,t,filters, out_channels,stride,block_id,LUtype='ReLU'):\n",
    "    y = expansion_block(x,t,filters,block_id,LUtype)\n",
    "    y = depthwise_block(y,stride,block_id,LUtype)\n",
    "    y = projection_block(y, out_channels,block_id)\n",
    "    if y.shape[-1]==x.shape[-1]:\n",
    "        y = add([x,y])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MobileNetV2(input_shape = (96,96,3), n_classes=2,LUtype='ReLU'):\n",
    "    input = Input(input_shape)\n",
    "\n",
    "    x = Conv2D(32,kernel_size=3,strides=(2,2),padding = 'same', use_bias=False)(input)\n",
    "    x = BatchNormalization(name='conv1_bn')(x)\n",
    "    if LUtype in stdactivators:\n",
    "        x = eval(LUtype + \"(6, name = 'conv1_relu')(x)\")\n",
    "    elif LUtype == 'PReLU':\n",
    "        x = PReLU(name='conv1_relu')(x)\n",
    "    elif LUtype == 'SeLU':\n",
    "        x = selu(x)\n",
    "    elif LUtype == 'Swish':\n",
    "        x = swish(x)\n",
    "\n",
    "\n",
    "    # 17 Bottlenecks\n",
    "\n",
    "    x = depthwise_block(x,stride=1,block_id=1,LUtype=LUtype)\n",
    "    x = projection_block(x, out_channels=16,block_id=1)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 24, stride = 2,block_id = 2,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 24, stride = 1,block_id = 3,LUtype=LUtype)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 2,block_id = 4,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 5,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 6,LUtype=LUtype)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 2,block_id = 7,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 8,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 9,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 10,LUtype=LUtype)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 11,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 12,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 13,LUtype=LUtype)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 2,block_id = 14,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 15,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 16,LUtype=LUtype)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 320, stride = 1,block_id = 17,LUtype=LUtype)\n",
    "\n",
    "\n",
    "    #1*1 conv\n",
    "    x = Conv2D(filters = 1280,kernel_size = 1,padding='same',use_bias=False, name = 'last_conv')(x)\n",
    "    x = BatchNormalization(name='last_bn')(x)\n",
    "    if LUtype in stdactivators:\n",
    "        x = eval(LUtype + \"(6, name = 'last_relu')(x)\")\n",
    "    elif LUtype == 'PReLU':\n",
    "        x = PReLU(name='last_relu')(x)\n",
    "    elif LUtype == 'SeLU':\n",
    "        x = selu(x)\n",
    "    elif LUtype == 'Swish':\n",
    "        x = swish(x)\n",
    "    \n",
    "\n",
    "    #AvgPool 7*7\n",
    "    x = GlobalAveragePooling2D(name='global_average_pool')(x)\n",
    "    output = Dense(n_classes,activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(input, output)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ImageGenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     train_path = os.path.join(base_dir, 'train')\n",
    "     valid_path = os.path.join(base_dir, 'valid')\n",
    "\n",
    "\n",
    "     RESCALING_FACTOR = 1./255\n",
    "\n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.8237 - precision: 0.8276 - recall: 0.8178 - auc: 0.9017 - false_negatives: 13121.0000 - false_positives: 12267.0000 - true_negatives: 59733.0000 - true_positives: 58879.0000\n",
      "Epoch 1: val_loss improved from inf to 0.78609, saving model to CNN_model_SeLU_weights.hdf5\n",
      "4500/4500 [==============================] - 2514s 557ms/step - loss: 0.3973 - accuracy: 0.8237 - precision: 0.8276 - recall: 0.8178 - auc: 0.9017 - false_negatives: 13121.0000 - false_positives: 12267.0000 - true_negatives: 59733.0000 - true_positives: 58879.0000 - val_loss: 0.7861 - val_accuracy: 0.6920 - val_precision: 0.9165 - val_recall: 0.4225 - val_auc: 0.8085 - val_false_negatives: 4620.0000 - val_false_positives: 308.0000 - val_true_negatives: 7692.0000 - val_true_positives: 3380.0000\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.3365 - accuracy: 0.8556 - precision: 0.8568 - recall: 0.8539 - auc: 0.9305 - false_negatives: 10522.0000 - false_positives: 10275.0000 - true_negatives: 61725.0000 - true_positives: 61478.0000\n",
      "Epoch 2: val_loss improved from 0.78609 to 0.33151, saving model to CNN_model_SeLU_weights.hdf5\n",
      "4500/4500 [==============================] - 2298s 511ms/step - loss: 0.3365 - accuracy: 0.8556 - precision: 0.8568 - recall: 0.8539 - auc: 0.9305 - false_negatives: 10522.0000 - false_positives: 10275.0000 - true_negatives: 61725.0000 - true_positives: 61478.0000 - val_loss: 0.3315 - val_accuracy: 0.8611 - val_precision: 0.8912 - val_recall: 0.8225 - val_auc: 0.9364 - val_false_negatives: 1420.0000 - val_false_positives: 803.0000 - val_true_negatives: 7197.0000 - val_true_positives: 6580.0000\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.8708 - precision: 0.8718 - recall: 0.8694 - auc: 0.9426 - false_negatives: 9406.0000 - false_positives: 9205.0000 - true_negatives: 62795.0000 - true_positives: 62594.0000\n",
      "Epoch 3: val_loss did not improve from 0.33151\n",
      "4500/4500 [==============================] - 2313s 514ms/step - loss: 0.3064 - accuracy: 0.8708 - precision: 0.8718 - recall: 0.8694 - auc: 0.9426 - false_negatives: 9406.0000 - false_positives: 9205.0000 - true_negatives: 62795.0000 - true_positives: 62594.0000 - val_loss: 0.8979 - val_accuracy: 0.6439 - val_precision: 0.5859 - val_recall: 0.9812 - val_auc: 0.8777 - val_false_negatives: 150.0000 - val_false_positives: 5548.0000 - val_true_negatives: 2452.0000 - val_true_positives: 7850.0000\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.8798 - precision: 0.8817 - recall: 0.8774 - auc: 0.9494 - false_negatives: 8827.0000 - false_positives: 8475.0000 - true_negatives: 63525.0000 - true_positives: 63173.0000\n",
      "Epoch 4: val_loss improved from 0.33151 to 0.32945, saving model to CNN_model_SeLU_weights.hdf5\n",
      "4500/4500 [==============================] - 2278s 506ms/step - loss: 0.2877 - accuracy: 0.8798 - precision: 0.8817 - recall: 0.8774 - auc: 0.9494 - false_negatives: 8827.0000 - false_positives: 8475.0000 - true_negatives: 63525.0000 - true_positives: 63173.0000 - val_loss: 0.3295 - val_accuracy: 0.8658 - val_precision: 0.9216 - val_recall: 0.7996 - val_auc: 0.9423 - val_false_negatives: 1603.0000 - val_false_positives: 544.0000 - val_true_negatives: 7456.0000 - val_true_positives: 6397.0000\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.8887 - precision: 0.8905 - recall: 0.8863 - auc: 0.9552 - false_negatives: 8185.0000 - false_positives: 7844.0000 - true_negatives: 64156.0000 - true_positives: 63815.0000\n",
      "Epoch 5: val_loss improved from 0.32945 to 0.27942, saving model to CNN_model_SeLU_weights.hdf5\n",
      "4500/4500 [==============================] - 2333s 519ms/step - loss: 0.2710 - accuracy: 0.8887 - precision: 0.8905 - recall: 0.8863 - auc: 0.9552 - false_negatives: 8185.0000 - false_positives: 7844.0000 - true_negatives: 64156.0000 - true_positives: 63815.0000 - val_loss: 0.2794 - val_accuracy: 0.8831 - val_precision: 0.9394 - val_recall: 0.8191 - val_auc: 0.9611 - val_false_negatives: 1447.0000 - val_false_positives: 423.0000 - val_true_negatives: 7577.0000 - val_true_positives: 6553.0000\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.8942 - precision: 0.8968 - recall: 0.8908 - auc: 0.9593 - false_negatives: 7859.0000 - false_positives: 7383.0000 - true_negatives: 64617.0000 - true_positives: 64141.0000\n",
      "Epoch 6: val_loss did not improve from 0.27942\n",
      "4500/4500 [==============================] - 2301s 511ms/step - loss: 0.2582 - accuracy: 0.8942 - precision: 0.8968 - recall: 0.8908 - auc: 0.9593 - false_negatives: 7859.0000 - false_positives: 7383.0000 - true_negatives: 64617.0000 - true_positives: 64141.0000 - val_loss: 0.3328 - val_accuracy: 0.8574 - val_precision: 0.8730 - val_recall: 0.8366 - val_auc: 0.9332 - val_false_negatives: 1307.0000 - val_false_positives: 974.0000 - val_true_negatives: 7026.0000 - val_true_positives: 6693.0000\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.9012 - precision: 0.9041 - recall: 0.8976 - auc: 0.9637 - false_negatives: 7373.0000 - false_positives: 6854.0000 - true_negatives: 65146.0000 - true_positives: 64627.0000\n",
      "Epoch 7: val_loss did not improve from 0.27942\n",
      "4500/4500 [==============================] - 2296s 510ms/step - loss: 0.2437 - accuracy: 0.9012 - precision: 0.9041 - recall: 0.8976 - auc: 0.9637 - false_negatives: 7373.0000 - false_positives: 6854.0000 - true_negatives: 65146.0000 - true_positives: 64627.0000 - val_loss: 0.3277 - val_accuracy: 0.8587 - val_precision: 0.8742 - val_recall: 0.8381 - val_auc: 0.9366 - val_false_negatives: 1295.0000 - val_false_positives: 965.0000 - val_true_negatives: 7035.0000 - val_true_positives: 6705.0000\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9059 - precision: 0.9089 - recall: 0.9023 - auc: 0.9666 - false_negatives: 7033.0000 - false_positives: 6514.0000 - true_negatives: 65486.0000 - true_positives: 64967.0000\n",
      "Epoch 8: val_loss improved from 0.27942 to 0.27876, saving model to CNN_model_SeLU_weights.hdf5\n",
      "4500/4500 [==============================] - 2341s 520ms/step - loss: 0.2336 - accuracy: 0.9059 - precision: 0.9089 - recall: 0.9023 - auc: 0.9666 - false_negatives: 7033.0000 - false_positives: 6514.0000 - true_negatives: 65486.0000 - true_positives: 64967.0000 - val_loss: 0.2788 - val_accuracy: 0.8819 - val_precision: 0.9330 - val_recall: 0.8229 - val_auc: 0.9589 - val_false_negatives: 1417.0000 - val_false_positives: 473.0000 - val_true_negatives: 7527.0000 - val_true_positives: 6583.0000\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.9111 - precision: 0.9137 - recall: 0.9080 - auc: 0.9698 - false_negatives: 6621.0000 - false_positives: 6176.0000 - true_negatives: 65824.0000 - true_positives: 65379.0000\n",
      "Epoch 9: val_loss improved from 0.27876 to 0.24361, saving model to CNN_model_SeLU_weights.hdf5\n",
      "4500/4500 [==============================] - 2317s 515ms/step - loss: 0.2221 - accuracy: 0.9111 - precision: 0.9137 - recall: 0.9080 - auc: 0.9698 - false_negatives: 6621.0000 - false_positives: 6176.0000 - true_negatives: 65824.0000 - true_positives: 65379.0000 - val_loss: 0.2436 - val_accuracy: 0.8984 - val_precision: 0.9392 - val_recall: 0.8520 - val_auc: 0.9675 - val_false_negatives: 1184.0000 - val_false_positives: 441.0000 - val_true_negatives: 7559.0000 - val_true_positives: 6816.0000\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.9162 - precision: 0.9198 - recall: 0.9119 - auc: 0.9726 - false_negatives: 6341.0000 - false_positives: 5728.0000 - true_negatives: 66272.0000 - true_positives: 65659.0000\n",
      "Epoch 10: val_loss did not improve from 0.24361\n",
      "4500/4500 [==============================] - 2292s 509ms/step - loss: 0.2111 - accuracy: 0.9162 - precision: 0.9198 - recall: 0.9119 - auc: 0.9726 - false_negatives: 6341.0000 - false_positives: 5728.0000 - true_negatives: 66272.0000 - true_positives: 65659.0000 - val_loss: 0.3283 - val_accuracy: 0.8703 - val_precision: 0.8167 - val_recall: 0.9549 - val_auc: 0.9550 - val_false_negatives: 361.0000 - val_false_positives: 1714.0000 - val_true_negatives: 6286.0000 - val_true_positives: 7639.0000\n"
     ]
    }
   ],
   "source": [
    "# the size of the images in the PCAM dataset\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "input = Input(input_shape)\n",
    "n_classes = 1\n",
    "LUtype = 'SeLU' \n",
    "model = MobileNetV2(input_shape,n_classes,LUtype)\n",
    "# model.summary()\n",
    "\n",
    "# Set up data generators\n",
    "train_gen, val_gen = get_pcam_generators(\"C:/Users/20201796/Documents/TUe/Year 3 BMT/Q3/8P361 - Project AI for medical image analysis/8p361-project-imaging-master\")\n",
    "\n",
    "model.compile(SGD(learning_rate=0.001,momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy', Precision(), Recall(), AUC(), FalseNegatives(), FalsePositives(), TrueNegatives(), TruePositives()])\n",
    "\n",
    "# save the model and weights\n",
    "model_name = 'CNN_model_SeLU'\n",
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "model_json = model.to_json() # serialize model to JSON\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "# train the model, note that we define \"mini-epochs\"\n",
    "train_steps = train_gen.n//train_gen.batch_size\n",
    "val_steps = val_gen.n//val_gen.batch_size\n",
    "\n",
    "# since the model is trained for only 10 \"mini-epochs\", i.e. half of the data is\n",
    "# not used during training\n",
    "history = model.fit(train_gen, steps_per_epoch=train_steps,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=10,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
