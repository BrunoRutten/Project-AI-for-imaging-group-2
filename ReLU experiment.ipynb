{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Notebook Group 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, ReLU, BatchNormalization, add,Softmax, AveragePooling2D, Dense, Input, GlobalAveragePooling2D,ELU,PReLU,LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# disable overly verbose tensorflow logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expansion_block(x,t,filters,block_id,LUtype):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    total_filters = t*filters\n",
    "    x = Conv2D(total_filters,1,padding='same',use_bias=False, name = prefix +'expand')(x)\n",
    "    x = BatchNormalization(name=prefix +'expand_bn')(x)\n",
    "    x = eval(LUtype + \"(6,name = prefix +'expand_relu')(x)\")\n",
    "    return x\n",
    "\n",
    "def depthwise_block(x,stride,block_id,LUtype):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = DepthwiseConv2D(3,strides=(stride,stride),padding ='same', use_bias = False, name = prefix + 'depthwise_conv')(x)\n",
    "    x = BatchNormalization(name=prefix +'dw_bn')(x)\n",
    "    x = eval(LUtype + \"(6,name=prefix +'dw_relu')(x)\")\n",
    "    return x\n",
    "\n",
    "def projection_block(x,out_channels,block_id):\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    x = Conv2D(filters = out_channels,kernel_size = 1,padding='same',use_bias=False,name= prefix + 'compress')(x)\n",
    "    x = BatchNormalization(name=prefix +'compress_bn')(x)\n",
    "    return x\n",
    "\n",
    "def Bottleneck(x,t,filters, out_channels,stride,block_id,LUtype='ReLU'):\n",
    "    y = expansion_block(x,t,filters,block_id,LUtype)\n",
    "    y = depthwise_block(y,stride,block_id,LUtype)\n",
    "    y = projection_block(y, out_channels,block_id)\n",
    "    if y.shape[-1]==x.shape[-1]:\n",
    "        y = add([x,y])\n",
    "    return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MobileNetV2(input_shape = (96,96,3), n_classes=2,LUtype='ReLU'):\n",
    "    input = Input(input_shape)\n",
    "\n",
    "    x = Conv2D(32,kernel_size=3,strides=(2,2),padding = 'same', use_bias=False)(input)\n",
    "    x = BatchNormalization(name='conv1_bn')(x)\n",
    "    x = ReLU(6, name = 'conv1_relu')(x)\n",
    "\n",
    "    # 17 Bottlenecks\n",
    "\n",
    "    x = depthwise_block(x,stride=1,block_id=1,LUtype=LUtype)\n",
    "    x = projection_block(x, out_channels=16,block_id=1)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 24, stride = 2,block_id = 2,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 24, stride = 1,block_id = 3,LUtype=LUtype)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 2,block_id = 4,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 5,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 6,LUtype=LUtype)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 2,block_id = 7,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 8,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 9,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 10,LUtype=LUtype)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 11,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 12,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 13,LUtype=LUtype)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 2,block_id = 14,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 15,LUtype=LUtype)\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 16,LUtype=LUtype)\n",
    "\n",
    "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 320, stride = 1,block_id = 17,LUtype=LUtype)\n",
    "\n",
    "\n",
    "    #1*1 conv\n",
    "    x = Conv2D(filters = 1280,kernel_size = 1,padding='same',use_bias=False, name = 'last_conv')(x)\n",
    "    x = BatchNormalization(name='last_bn')(x)\n",
    "    x = ReLU(6,name='last_relu')(x)\n",
    "\n",
    "    #AvgPool 7*7\n",
    "    x = GlobalAveragePooling2D(name='global_average_pool')(x)\n",
    "\n",
    "    output = Dense(n_classes,activation='softmax')(x)\n",
    "\n",
    "    model = Model(input, output)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ImageGenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     train_path = os.path.join(base_dir, 'train')\n",
    "     valid_path = os.path.join(base_dir, 'valid')\n",
    "\n",
    "\n",
    "     RESCALING_FACTOR = 1./255\n",
    "\n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     return train_gen, val_gen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the size of the images in the PCAM dataset\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "input = Input(input_shape)\n",
    "n_classes = 1\n",
    "LUtype = 'LeakyReLU' # TODO PreLU has different parameters, so it is not implemented. Swish and SELU are not implemented either.\n",
    "model = MobileNetV2(input_shape,n_classes,LUtype)\n",
    "# model.summary()\n",
    "\n",
    "# Set up data generators\n",
    "train_gen, val_gen = get_pcam_generators('C:/Users/20202181/OneDrive - TU Eindhoven/Desktop/Project imaging/train+val')\n",
    "\n",
    "model.compile(SGD(learning_rate=0.001, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# save the model and weights\n",
    "model_name = 'CNN_model_ReLU'\n",
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "model_json = model.to_json() # serialize model to JSON\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "# train the model, note that we define \"mini-epochs\"\n",
    "train_steps = train_gen.n//train_gen.batch_size\n",
    "val_steps = val_gen.n//val_gen.batch_size\n",
    "\n",
    "# since the model is trained for only 10 \"mini-epochs\", i.e. half of the data is\n",
    "# not used during training\n",
    "history = model.fit(train_gen, steps_per_epoch=train_steps,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=10,\n",
    "                    callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
